{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# video Style Transfer Implementation\n",
    "import torch\n",
    "import utils\n",
    "import transformer\n",
    "import os\n",
    "import time\n",
    "import cv2\n",
    "import numpy as np\n",
    "import re\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set configuration\n",
    "STYLE_TRANSFORM_PATH = \"transforms/starry.pth\"  # style model\n",
    "PRESERVE_COLOR = False\n",
    "CONTENT_FRAMES_DIR = \"frames/content_folder\"\n",
    "STYLE_FRAMES_DIR = \"style_frames\"\n",
    "OUTPUT_FRAMES_DIR = \"frames/output_folder\"\n",
    "VIDEOS_INPUT_DIR = \"videos/input\"\n",
    "VIDEOS_OUTPUT_DIR = \"videos/output\"\n",
    "TEMPORAL_WEIGHT = 0.5  # Weight for temporal consistency"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def natural_sort_key(s):\n",
    "    \"\"\"\n",
    "    Natural sort key function for sorting file names with numbers\n",
    "    \"\"\"\n",
    "    return [int(text) if text.isdigit() else text.lower() for text in re.split(r'(\\d+)', s)]\n",
    "\n",
    "def ensure_dir(directory):\n",
    "    \"\"\"Create directory if it doesn't exist\"\"\"\n",
    "    if not os.path.exists(directory):\n",
    "        os.makedirs(directory)\n",
    "\n",
    "def load_image_from_array(img_array):\n",
    "    \"\"\"Load PIL image from numpy array\"\"\"\n",
    "    return Image.fromarray(img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VideoStyleTransfer:\n",
    "    def __init__(self, style_model_path, device=None, preserve_color=False):\n",
    "        \"\"\"Initialize the video style transfer model\"\"\"\n",
    "        self.device = device if device else (\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "        print(f\"Using device: {self.device}\")\n",
    "        \n",
    "        # Load transformer network\n",
    "        print(\"Loading transformer network...\")\n",
    "        self.net = transformer.TransformerNetwork()\n",
    "        self.net.load_state_dict(torch.load(style_model_path))\n",
    "        self.net = self.net.to(self.device)\n",
    "        self.net.eval()  # Set to evaluation mode\n",
    "        \n",
    "        self.preserve_color = preserve_color\n",
    "        self.prev_stylized = None  # Store previous stylized frame for temporal consistency\n",
    "    \n",
    "    def stylize_frame(self, frame, apply_temporal=True):\n",
    "        \"\"\"\n",
    "        Stylize a single video frame\n",
    "        \n",
    "        Args:\n",
    "            frame: OpenCV frame in BGR format\n",
    "            apply_temporal: Whether to apply temporal consistency\n",
    "            \n",
    "        Returns:\n",
    "            Stylized frame in BGR format\n",
    "        \"\"\"\n",
    "        # Convert BGR to RGB\n",
    "        frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        # Convert to PIL Image\n",
    "        content_image = load_image_from_array(frame_rgb)\n",
    "        \n",
    "        # Apply style transfer\n",
    "        content_tensor = utils.itot(content_image).to(self.device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            stylized_tensor = self.net(content_tensor)\n",
    "        \n",
    "        # Apply temporal consistency if needed\n",
    "        if apply_temporal and self.prev_stylized is not None:\n",
    "            stylized_tensor = (1 - TEMPORAL_WEIGHT) * stylized_tensor + TEMPORAL_WEIGHT * self.prev_stylized\n",
    "        \n",
    "        # Store current output for next frame\n",
    "        self.prev_stylized = stylized_tensor.clone()\n",
    "        \n",
    "        # Convert back to image\n",
    "        stylized_image = utils.ttoi(stylized_tensor.detach())\n",
    "        \n",
    "        if self.preserve_color:\n",
    "            stylized_image = utils.transfer_color(content_image, stylized_image)\n",
    "        \n",
    "        # Convert back to BGR for OpenCV\n",
    "        stylized_frame = cv2.cvtColor(np.array(stylized_image), cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        return stylized_frame\n",
    "    \n",
    "    def process_video(self, input_path, output_path):\n",
    "        \"\"\"Process an entire video with style transfer\"\"\"\n",
    "        # Open video file\n",
    "        video = cv2.VideoCapture(input_path)\n",
    "        if not video.isOpened():\n",
    "            print(f\"Error: Could not open video file {input_path}\")\n",
    "            return\n",
    "        \n",
    "        # Get video properties\n",
    "        width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = video.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        print(f\"Video properties: {width}x{height}, {fps} fps, {total_frames} frames\")\n",
    "        \n",
    "        # Create output directory if it doesn't exist\n",
    "        ensure_dir(os.path.dirname(output_path))\n",
    "        \n",
    "        # Create video writer\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "        \n",
    "        if not out.isOpened():\n",
    "            print(f\"Error: Could not create output video file {output_path}\")\n",
    "            video.release()\n",
    "            return\n",
    "        \n",
    "        frame_count = 0\n",
    "        processing_times = []\n",
    "        \n",
    "        print(\"Processing video...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        while True:\n",
    "            ret, frame = video.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame_start = time.time()\n",
    "            \n",
    "            # Apply style transfer\n",
    "            stylized_frame = self.stylize_frame(frame, apply_temporal=(frame_count > 0))\n",
    "            \n",
    "            # Ensure frame is 8-bit unsigned integer format (CV_8U)\n",
    "            if stylized_frame.dtype != np.uint8:\n",
    "                stylized_frame = np.clip(stylized_frame, 0, 255).astype(np.uint8)\n",
    "            \n",
    "            # Write frame to output video\n",
    "            out.write(stylized_frame)\n",
    "            \n",
    "            # Calculate processing time\n",
    "            frame_time = time.time() - frame_start\n",
    "            processing_times.append(frame_time)\n",
    "            \n",
    "            # Show progress\n",
    "            frame_count += 1\n",
    "            if frame_count % 10 == 0 or frame_count == total_frames:\n",
    "                elapsed = time.time() - start_time\n",
    "                estimated_total = elapsed / frame_count * total_frames\n",
    "                remaining = estimated_total - elapsed\n",
    "                print(f\"Processed frame {frame_count}/{total_frames} - \"\n",
    "                      f\"Avg. time per frame: {np.mean(processing_times):.3f}s - \"\n",
    "                      f\"Remaining time: {remaining/60:.1f} min\")\n",
    "        \n",
    "        # Release resources\n",
    "        video.release()\n",
    "        out.release()\n",
    "        \n",
    "        # Print stats\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"Video processing completed in {total_time:.2f} seconds\")\n",
    "        print(f\"Average processing time per frame: {np.mean(processing_times):.3f} seconds\")\n",
    "        print(f\"Stylized video saved to: {output_path}\")\n",
    "        \n",
    "        return output_path\n",
    "    \n",
    "    def process_frame_directory(self, input_dir, output_dir):\n",
    "        \"\"\"Process all frames in a directory\"\"\"\n",
    "        # Get all frame files\n",
    "        frame_files = glob.glob(os.path.join(input_dir, \"*.jpg\")) + \\\n",
    "                     glob.glob(os.path.join(input_dir, \"*.png\"))\n",
    "        frame_files = sorted(frame_files, key=natural_sort_key)\n",
    "        \n",
    "        if not frame_files:\n",
    "            print(f\"Error: No frames found in {input_dir}\")\n",
    "            return\n",
    "        \n",
    "        ensure_dir(output_dir)\n",
    "        \n",
    "        total_frames = len(frame_files)\n",
    "        processing_times = []\n",
    "        \n",
    "        print(f\"Processing {total_frames} frames...\")\n",
    "        start_time = time.time()\n",
    "        \n",
    "        for i, frame_path in enumerate(frame_files):\n",
    "            frame_start = time.time()\n",
    "            \n",
    "            # Read frame\n",
    "            frame = cv2.imread(frame_path)\n",
    "            \n",
    "            # Apply style transfer\n",
    "            stylized_frame = self.stylize_frame(frame, apply_temporal=(i > 0))\n",
    "            \n",
    "            # Ensure frame is 8-bit unsigned integer format (CV_8U)\n",
    "            if stylized_frame.dtype != np.uint8:\n",
    "                stylized_frame = np.clip(stylized_frame, 0, 255).astype(np.uint8)\n",
    "            \n",
    "            # Save stylized frame\n",
    "            output_path = os.path.join(output_dir, os.path.basename(frame_path))\n",
    "            cv2.imwrite(output_path, stylized_frame)\n",
    "            \n",
    "            # Calculate processing time\n",
    "            frame_time = time.time() - frame_start\n",
    "            processing_times.append(frame_time)\n",
    "            \n",
    "            # Show progress\n",
    "            if (i + 1) % 10 == 0 or (i + 1) == len(frame_files):\n",
    "                elapsed = time.time() - start_time\n",
    "                estimated_total = elapsed / (i + 1) * len(frame_files)\n",
    "                remaining = estimated_total - elapsed\n",
    "                print(f\"Processed frame {i+1}/{len(frame_files)} - \"\n",
    "                      f\"Avg. time per frame: {np.mean(processing_times):.3f}s - \"\n",
    "                      f\"Remaining time: {remaining/60:.1f} min\")\n",
    "        \n",
    "        # Print stats\n",
    "        total_time = time.time() - start_time\n",
    "        print(f\"Frame processing completed in {total_time:.2f} seconds\")\n",
    "        print(f\"Average processing time per frame: {np.mean(processing_times):.3f} seconds\")\n",
    "        print(f\"Stylized frames saved to: {output_dir}\")\n",
    "        \n",
    "        return output_dir\n",
    "    \n",
    "    def extract_process_combine(self, input_path, output_path, temp_dir=None):\n",
    "        \"\"\"\n",
    "        Extract frames, process them, and recombine into a video\n",
    "        This approach can be more memory-efficient for very large videos\n",
    "        \"\"\"\n",
    "        # Create temp directory if needed\n",
    "        if temp_dir is None:\n",
    "            temp_dir = \"temp_frames\"\n",
    "        ensure_dir(temp_dir)\n",
    "        \n",
    "        # Extract frames from video\n",
    "        video = cv2.VideoCapture(input_path)\n",
    "        if not video.isOpened():\n",
    "            print(f\"Error: Could not open video file {input_path}\")\n",
    "            return\n",
    "        \n",
    "        # Get video properties\n",
    "        width = int(video.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(video.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = video.get(cv2.CAP_PROP_FPS)\n",
    "        total_frames = int(video.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        \n",
    "        print(f\"Video properties: {width}x{height}, {fps} fps, {total_frames} frames\")\n",
    "        print(f\"Extracting frames to {temp_dir}...\")\n",
    "        \n",
    "        # Extract frames\n",
    "        frame_count = 0\n",
    "        while True:\n",
    "            ret, frame = video.read()\n",
    "            if not ret:\n",
    "                break\n",
    "            \n",
    "            frame_path = os.path.join(temp_dir, f\"frame_{frame_count:06d}.jpg\")\n",
    "            cv2.imwrite(frame_path, frame)\n",
    "            \n",
    "            frame_count += 1\n",
    "            if frame_count % 100 == 0:\n",
    "                print(f\"Extracted {frame_count}/{total_frames} frames\")\n",
    "        \n",
    "        video.release()\n",
    "        print(f\"Extracted {frame_count} frames\")\n",
    "        \n",
    "        # Process frames\n",
    "        print(\"Processing frames...\")\n",
    "        output_dir = os.path.join(temp_dir, \"stylized\")\n",
    "        ensure_dir(output_dir)\n",
    "        \n",
    "        frame_paths = [os.path.join(temp_dir, f) for f in os.listdir(temp_dir) \n",
    "                      if f.startswith(\"frame_\") and f.endswith(\".jpg\")]\n",
    "        frame_paths = sorted(frame_paths, key=natural_sort_key)\n",
    "        \n",
    "        start_time = time.time()\n",
    "        processing_times = []\n",
    "        \n",
    "        for i, frame_path in enumerate(frame_paths):\n",
    "            frame_start = time.time()\n",
    "            \n",
    "            # Read frame\n",
    "            frame = cv2.imread(frame_path)\n",
    "            \n",
    "            # Apply style transfer\n",
    "            stylized_frame = self.stylize_frame(frame, apply_temporal=(i > 0))\n",
    "            \n",
    "            # Ensure frame is 8-bit unsigned integer format (CV_8U)\n",
    "            if stylized_frame.dtype != np.uint8:\n",
    "                stylized_frame = np.clip(stylized_frame, 0, 255).astype(np.uint8)\n",
    "            \n",
    "            # Save stylized frame\n",
    "            output_path_frame = os.path.join(output_dir, os.path.basename(frame_path))\n",
    "            cv2.imwrite(output_path_frame, stylized_frame)\n",
    "            \n",
    "            # Calculate processing time\n",
    "            frame_time = time.time() - frame_start\n",
    "            processing_times.append(frame_time)\n",
    "            \n",
    "            # Show progress\n",
    "            if (i + 1) % 10 == 0 or (i + 1) == len(frame_paths):\n",
    "                elapsed = time.time() - start_time\n",
    "                estimated_total = elapsed / (i + 1) * len(frame_paths)\n",
    "                remaining = estimated_total - elapsed\n",
    "                print(f\"Processed frame {i+1}/{len(frame_paths)} - \"\n",
    "                      f\"Avg. time per frame: {np.mean(processing_times):.3f}s - \"\n",
    "                      f\"Remaining time: {remaining/60:.1f} min\")\n",
    "        \n",
    "        # Recombine frames into video\n",
    "        print(\"Recombining frames into video...\")\n",
    "        \n",
    "        # Get all stylized frames\n",
    "        stylized_paths = [os.path.join(output_dir, f) for f in os.listdir(output_dir) \n",
    "                         if f.startswith(\"frame_\") and f.endswith(\".jpg\")]\n",
    "        stylized_paths = sorted(stylized_paths, key=natural_sort_key)\n",
    "        \n",
    "        # Create video writer\n",
    "        ensure_dir(os.path.dirname(output_path))\n",
    "        fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "        \n",
    "        if not out.isOpened():\n",
    "            print(f\"Error: Could not create output video file {output_path}\")\n",
    "            return\n",
    "        \n",
    "        for frame_path in stylized_paths:\n",
    "            frame = cv2.imread(frame_path)\n",
    "            out.write(frame)\n",
    "        \n",
    "        out.release()\n",
    "        \n",
    "        print(f\"Video saved to {output_path}\")\n",
    "        \n",
    "        # Ask if user wants to delete temporary frames\n",
    "        response = input(\"Delete temporary frames? (y/n): \")\n",
    "        if response.lower() == 'y':\n",
    "            import shutil\n",
    "            shutil.rmtree(temp_dir)\n",
    "            print(f\"Deleted temporary frames directory: {temp_dir}\")\n",
    "        \n",
    "        return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stylize_video(input_path=None, output_path=None, style_path=None, preserve_color=False, \n",
    "                 temporal_weight=0.5, method=\"direct\"):\n",
    "    \"\"\"\n",
    "    Top-level function to stylize a video\n",
    "    \n",
    "    Args:\n",
    "        input_path: Path to input video\n",
    "        output_path: Path to save stylized video\n",
    "        style_path: Path to style model\n",
    "        preserve_color: Whether to preserve original colors\n",
    "        temporal_weight: Weight for temporal consistency (0-1)\n",
    "        method: \"direct\" or \"extract\" for processing method\n",
    "    \"\"\"\n",
    "    # Set default paths if not provided\n",
    "    if input_path is None:\n",
    "        input_path = os.path.join(VIDEOS_INPUT_DIR, \"boat.mp4\")\n",
    "    \n",
    "    if output_path is None:\n",
    "        # Create output path based on input\n",
    "        video_name = os.path.basename(input_path)\n",
    "        output_path = os.path.join(VIDEOS_OUTPUT_DIR, f\"stylized_{video_name}\")\n",
    "    \n",
    "    if style_path is None:\n",
    "        style_path = STYLE_TRANSFORM_PATH\n",
    "    \n",
    "    # Update global variables\n",
    "    global PRESERVE_COLOR, TEMPORAL_WEIGHT\n",
    "    PRESERVE_COLOR = preserve_color\n",
    "    TEMPORAL_WEIGHT = temporal_weight\n",
    "    \n",
    "    # Initialize model\n",
    "    model = VideoStyleTransfer(style_path, preserve_color=preserve_color)\n",
    "    \n",
    "    # Process video\n",
    "    if method == \"direct\":\n",
    "        return model.process_video(input_path, output_path)\n",
    "    else:\n",
    "        return model.extract_process_combine(input_path, output_path)\n",
    "\n",
    "def stylize_frames(input_dir=None, output_dir=None, style_path=None, preserve_color=False,\n",
    "                  temporal_weight=0.5):\n",
    "    \"\"\"\n",
    "    Top-level function to stylize frames in a directory\n",
    "    \n",
    "    Args:\n",
    "        input_dir: Directory containing input frames\n",
    "        output_dir: Directory to save stylized frames\n",
    "        style_path: Path to style model\n",
    "        preserve_color: Whether to preserve original colors\n",
    "        temporal_weight: Weight for temporal consistency (0-1)\n",
    "    \"\"\"\n",
    "    # Set default paths if not provided\n",
    "    if input_dir is None:\n",
    "        input_dir = CONTENT_FRAMES_DIR\n",
    "    \n",
    "    if output_dir is None:\n",
    "        output_dir = OUTPUT_FRAMES_DIR\n",
    "    \n",
    "    if style_path is None:\n",
    "        style_path = STYLE_TRANSFORM_PATH\n",
    "    \n",
    "    # Update global variables\n",
    "    global PRESERVE_COLOR, TEMPORAL_WEIGHT\n",
    "    PRESERVE_COLOR = preserve_color\n",
    "    TEMPORAL_WEIGHT = temporal_weight\n",
    "    \n",
    "    # Initialize model\n",
    "    model = VideoStyleTransfer(style_path, preserve_color=preserve_color)\n",
    "    \n",
    "    # Process frames\n",
    "    return model.process_frame_directory(input_dir, output_dir)\n",
    "\n",
    "def frames_to_video(frames_dir, output_path, fps=30):\n",
    "    \"\"\"\n",
    "    Convert a directory of frames to a video\n",
    "    \n",
    "    Args:\n",
    "        frames_dir: Directory containing frame images\n",
    "        output_path: Path to save output video\n",
    "        fps: Frames per second for output video\n",
    "    \"\"\"\n",
    "    # Get all frame files\n",
    "    frame_files = glob.glob(os.path.join(frames_dir, \"*.jpg\")) + \\\n",
    "                 glob.glob(os.path.join(frames_dir, \"*.png\"))\n",
    "    frame_files = sorted(frame_files, key=natural_sort_key)\n",
    "    \n",
    "    if not frame_files:\n",
    "        print(f\"Error: No frames found in {frames_dir}\")\n",
    "        return\n",
    "    \n",
    "    # Get frame dimensions from the first frame\n",
    "    frame = cv2.imread(frame_files[0])\n",
    "    height, width, _ = frame.shape\n",
    "    \n",
    "    # Create video writer\n",
    "    ensure_dir(os.path.dirname(output_path))\n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
    "    out = cv2.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "    \n",
    "    if not out.isOpened():\n",
    "        print(f\"Error: Could not create output video file {output_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Converting {len(frame_files)} frames to video...\")\n",
    "    \n",
    "    for frame_path in frame_files:\n",
    "        frame = cv2.imread(frame_path)\n",
    "        out.write(frame)\n",
    "    \n",
    "    out.release()\n",
    "    print(f\"Video saved to: {output_path}\")\n",
    "    return output_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EXAMPLE 1: Direct video stylization\n",
      "Using device: cuda\n",
      "Loading transformer network...\n",
      "Video properties: 1920x1080, 29.97002997002997 fps, 301 frames\n",
      "Processing video...\n",
      "Processed frame 10/301 - Avg. time per frame: 0.154s - Remaining time: 0.8 min\n",
      "Processed frame 20/301 - Avg. time per frame: 0.155s - Remaining time: 0.8 min\n",
      "Processed frame 30/301 - Avg. time per frame: 0.156s - Remaining time: 0.7 min\n",
      "Processed frame 40/301 - Avg. time per frame: 0.157s - Remaining time: 0.7 min\n",
      "Processed frame 50/301 - Avg. time per frame: 0.157s - Remaining time: 0.7 min\n",
      "Processed frame 60/301 - Avg. time per frame: 0.156s - Remaining time: 0.6 min\n",
      "Processed frame 70/301 - Avg. time per frame: 0.158s - Remaining time: 0.6 min\n",
      "Processed frame 80/301 - Avg. time per frame: 0.158s - Remaining time: 0.6 min\n",
      "Processed frame 90/301 - Avg. time per frame: 0.160s - Remaining time: 0.6 min\n",
      "Processed frame 100/301 - Avg. time per frame: 0.160s - Remaining time: 0.5 min\n",
      "Processed frame 110/301 - Avg. time per frame: 0.161s - Remaining time: 0.5 min\n",
      "Processed frame 120/301 - Avg. time per frame: 0.160s - Remaining time: 0.5 min\n",
      "Processed frame 130/301 - Avg. time per frame: 0.161s - Remaining time: 0.5 min\n",
      "Processed frame 140/301 - Avg. time per frame: 0.161s - Remaining time: 0.4 min\n",
      "Processed frame 150/301 - Avg. time per frame: 0.161s - Remaining time: 0.4 min\n",
      "Processed frame 160/301 - Avg. time per frame: 0.161s - Remaining time: 0.4 min\n",
      "Processed frame 170/301 - Avg. time per frame: 0.161s - Remaining time: 0.4 min\n",
      "Processed frame 180/301 - Avg. time per frame: 0.161s - Remaining time: 0.3 min\n",
      "Processed frame 190/301 - Avg. time per frame: 0.161s - Remaining time: 0.3 min\n",
      "Processed frame 200/301 - Avg. time per frame: 0.161s - Remaining time: 0.3 min\n",
      "Processed frame 210/301 - Avg. time per frame: 0.161s - Remaining time: 0.2 min\n",
      "Processed frame 220/301 - Avg. time per frame: 0.162s - Remaining time: 0.2 min\n",
      "Processed frame 230/301 - Avg. time per frame: 0.162s - Remaining time: 0.2 min\n",
      "Processed frame 240/301 - Avg. time per frame: 0.161s - Remaining time: 0.2 min\n",
      "Processed frame 250/301 - Avg. time per frame: 0.161s - Remaining time: 0.1 min\n",
      "Processed frame 260/301 - Avg. time per frame: 0.161s - Remaining time: 0.1 min\n",
      "Processed frame 270/301 - Avg. time per frame: 0.161s - Remaining time: 0.1 min\n",
      "Processed frame 280/301 - Avg. time per frame: 0.162s - Remaining time: 0.1 min\n",
      "Processed frame 290/301 - Avg. time per frame: 0.162s - Remaining time: 0.0 min\n",
      "Processed frame 300/301 - Avg. time per frame: 0.162s - Remaining time: 0.0 min\n",
      "Processed frame 301/301 - Avg. time per frame: 0.162s - Remaining time: 0.0 min\n",
      "Video processing completed in 49.63 seconds\n",
      "Average processing time per frame: 0.162 seconds\n",
      "Stylized video saved to: videos/output/coffee_shop_starry.mp4\n",
      "Stylized video saved to: videos/output/coffee_shop_starry.mp4\n"
     ]
    }
   ],
   "source": [
    "# Ensure directories exist\n",
    "ensure_dir(VIDEOS_INPUT_DIR)\n",
    "ensure_dir(VIDEOS_OUTPUT_DIR)\n",
    "\n",
    "# Example 1: Stylize a video directly\n",
    "print(\"EXAMPLE 1: Direct video stylization\")\n",
    "input_video = os.path.join(VIDEOS_INPUT_DIR, \"coffee_shop.mp4\")\n",
    "output_video = os.path.join(VIDEOS_OUTPUT_DIR, \"coffee_shop_starry.mp4\")\n",
    "\n",
    "stylized_path = stylize_video(\n",
    "    input_path=input_video,\n",
    "    output_path=output_video,\n",
    "    style_path=STYLE_TRANSFORM_PATH,\n",
    "    preserve_color=False,\n",
    "    temporal_weight=0.5,\n",
    "    method=\"direct\"\n",
    ")\n",
    "print(f\"Stylized video saved to: {stylized_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
